{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aafda8b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_decomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CCA\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "##library importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import datetime as dt\n",
    "import dateutil.easter as ea\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c8dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data importing and type casting\n",
    "\n",
    "forecastdemand_nsw = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Academic\\Final project\\Data\\forecastdemand_nsw.csv')\n",
    "\n",
    "temperature_nsw = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Academic\\Final project\\Data\\temperature_nsw.csv')\n",
    "\n",
    "truedemand_nsw = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Academic\\Final project\\Data\\totaldemand_nsw.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e373aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now have all data in respective data frames\n",
    "## alter datetimes fields to datetime data type\n",
    "\n",
    "forecastdemand_nsw['DATETIME'] = forecastdemand_nsw['DATETIME'].apply(lambda x: pd.to_datetime(x))\n",
    "forecastdemand_nsw['LASTCHANGED'] = forecastdemand_nsw['LASTCHANGED'].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "temperature_nsw['DATETIME'] = temperature_nsw['DATETIME'].apply(lambda x: pd.to_datetime(x))\n",
    "##temperature_nsw['ADJUSTED_DATETIME'] = temperature_nsw['DATETIME'].apply(lambda x: pd.datetime(x.year\n",
    "##                                                                                               ,x.month\n",
    "##                                                                                               ,x.day\n",
    "##                                                                                               ,x.hour\n",
    "##                                                                                               ,0\n",
    "##                                                                                               ,x.second) \n",
    "##                                                                                               + np.timedelta64(30*round(x.minute/30),'m'))\n",
    "temperature_nsw['MINUTE'] = temperature_nsw['DATETIME'].apply(lambda x:x.minute)\n",
    "\n",
    "truedemand_nsw['DATETIME'] = truedemand_nsw['DATETIME'].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "##prep temperature data for interpolating by removing erroneous data points (e.g. one temp was -9999)\n",
    "temperature_nsw = temperature_nsw[temperature_nsw['TEMPERATURE']>-30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e8e8ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATETIME       datetime64[ns]\n",
      "REGIONID              float64\n",
      "TOTALDEMAND           float64\n",
      "DATEINT                 int64\n",
      "dtype: object\n",
      "DATETIME            datetime64[ns]\n",
      "REGIONID                    object\n",
      "FORECASTDEMAND             float64\n",
      "PREDISPATCHSEQNO             int64\n",
      "PERIODID                     int64\n",
      "LASTCHANGED         datetime64[ns]\n",
      "DATEINT                      int64\n",
      "dtype: object\n",
      "                 DATETIME_X REGIONID_X  FORECASTDEMAND  PREDISPATCHSEQNO  \\\n",
      "68      2010-01-01 00:00:00       NSW1         7999.11        2009123140   \n",
      "138     2010-01-01 00:30:00       NSW1         7596.21        2009123141   \n",
      "209     2010-01-01 01:00:00       NSW1         7380.70        2009123142   \n",
      "281     2010-01-01 01:30:00       NSW1         7022.05        2009123143   \n",
      "354     2010-01-01 02:00:00       NSW1         6682.92        2009123144   \n",
      "...                     ...        ...             ...               ...   \n",
      "1323119 2011-05-12 17:30:00       NSW1        10701.35        2011051227   \n",
      "1323178 2011-05-12 18:00:00       NSW1        11461.44        2011051228   \n",
      "1323238 2011-05-12 18:30:00       NSW1        11809.56        2011051229   \n",
      "1323299 2011-05-12 19:00:00       NSW1        11741.12        2011051230   \n",
      "1323361 2011-05-12 19:30:00       NSW1        11534.14        2011051231   \n",
      "\n",
      "         PERIODID         LASTCHANGED            DATEINT_X  \\\n",
      "68              1 2009-12-31 23:31:32  1262304000000000000   \n",
      "138             1 2010-01-01 00:01:24  1262305800000000000   \n",
      "209             1 2010-01-01 00:31:30  1262307600000000000   \n",
      "281             1 2010-01-01 01:01:21  1262309400000000000   \n",
      "354             1 2010-01-01 01:31:24  1262311200000000000   \n",
      "...           ...                 ...                  ...   \n",
      "1323119         1 2011-05-12 17:01:16  1305221400000000000   \n",
      "1323178         1 2011-05-12 17:31:22  1305223200000000000   \n",
      "1323238         1 2011-05-12 18:01:26  1305225000000000000   \n",
      "1323299         1 2011-05-12 18:31:14  1305226800000000000   \n",
      "1323361         1 2011-05-12 19:01:16  1305228600000000000   \n",
      "\n",
      "                 DATETIME_Y  REGIONID_Y  TOTALDEMAND            DATEINT_Y  \n",
      "68      2010-01-01 05:40:00         NaN      6359.62  1262324400000000000  \n",
      "138     2010-01-01 11:30:00         NaN      8275.15  1262345400000000000  \n",
      "209     2010-01-01 17:25:00         NaN      8788.31  1262366700000000000  \n",
      "281     2010-01-01 23:25:00         NaN      7733.24  1262388300000000000  \n",
      "354     2010-01-02 05:30:00         NaN      6377.68  1262410200000000000  \n",
      "...                     ...         ...          ...                  ...  \n",
      "1323119 2022-07-31 00:50:00         NaN      8440.12  1659228600000000000  \n",
      "1323178 2022-07-31 05:45:00         NaN      7494.40  1659246300000000000  \n",
      "1323238 2022-07-31 10:45:00         NaN      8503.42  1659264300000000000  \n",
      "1323299 2022-07-31 15:50:00         NaN      9131.09  1659282600000000000  \n",
      "1323361 2022-07-31 21:00:00         NaN      9724.55  1659301200000000000  \n",
      "\n",
      "[23848 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "P1_forecast_demand = pd.DataFrame(forecastdemand_nsw[forecastdemand_nsw['PERIODID'] ==1],columns=forecastdemand_nsw.columns)\n",
    "P1_forecast_demand['DATEINT'] = forecastdemand_nsw['DATETIME'].astype(np.int64)\n",
    "P1_true_demand = pd.DataFrame(truedemand_nsw[['DATETIME','TOTALDEMAND']],columns = truedemand_nsw.columns)\n",
    "P1_true_demand['DATEINT'] = truedemand_nsw['DATETIME'].astype(np.int64)\n",
    "                                                                                    \n",
    "print(P1_true_demand.dtypes)\n",
    "print(P1_forecast_demand.dtypes)\n",
    "comp_set = P1_forecast_demand.join(P1_true_demand,how = 'inner',lsuffix = '_X',rsuffix = '_Y')\n",
    "mean_squared_error(comp_set['TOTALDEMAND'],comp_set['FORECASTDEMAND'])\n",
    "\n",
    "##print(comp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f89244",
   "metadata": {},
   "outputs": [],
   "source": [
    "##public holiday determination\n",
    "\n",
    "def public_holiday_check(new_date_check: str):\n",
    "    new_date = pd.Timestamp(new_date_check)\n",
    "    ##new year and australia day\n",
    "    if new_date.month == 1:\n",
    "        if new_date.weekday() not in (5,6):\n",
    "            if new_date.day in (1,26):\n",
    "                return(1)\n",
    "        elif new_date.weekday() == 5:\n",
    "            if new_date.day in (3,28):\n",
    "                return(1)\n",
    "        else:\n",
    "            if new_date.day in (2,27):\n",
    "                return(1)\n",
    "    if new_date.month == 3 & ea.easter(new_date.year).month ==3:\n",
    "        if new_date.day in range(ea.easter(new_date.year).day-2,ea.easter(new_date.year).day+1):\n",
    "            return(1)\n",
    "    ##Anzac day\n",
    "    if new_date.month == 4:\n",
    "        if new_date.weekday() not in (5,6):\n",
    "            if new_date.day == 25:\n",
    "                return(1)\n",
    "        elif new_date.weekday() == 6:\n",
    "            if new_date.day == 26:\n",
    "                return(1)\n",
    "        else:\n",
    "            if new_date.day == 27:\n",
    "                return(1)\n",
    "        if ea.easter(new_date.year).month == 4:\n",
    "            if new_date.day in range(ea.easter(new_date.year).day-2,ea.easter(new_date.year).day+1):\n",
    "                return(1)\n",
    "    ## king/queen birthday\n",
    "    if new_date.month == 6 & new_date.day > 7 & new_date.day < 15 & new_date.weekday() == 0:\n",
    "        return(1)\n",
    "    ##Labour day\n",
    "    if new_date.month == 10 & new_date.day < 8 & new_date.weekday() == 0:\n",
    "        return(1)\n",
    "    ##christmas and boxing day\n",
    "    if new_date.month == 12:\n",
    "        if new_date.weekday() not in (5,6):\n",
    "            if new_date.day in (25,26):\n",
    "                return(1)\n",
    "        elif new_date.weekday() == 5:\n",
    "            if new_date.day in (27,28):\n",
    "                return(1)\n",
    "        else:\n",
    "            if new_date.day in (26,27):\n",
    "                return(1)\n",
    "    return(0)\n",
    "truedemand_nsw['public_holiday'] = truedemand_nsw['DATETIME'].apply(lambda x: public_holiday_check(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e970ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "          ..\n",
       "1323393    0\n",
       "1323394    0\n",
       "1323395    0\n",
       "1323396    0\n",
       "1323397    0\n",
       "Name: public_holiday, Length: 1323398, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truedemand_nsw['public_holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c944158",
   "metadata": {},
   "outputs": [],
   "source": [
    "## temperature interpolation  to create temperatures that match the times of demands\n",
    "## first model will be a basic linear combintion of nearest two surrounding existing temperatures\n",
    "## will over fit and assumes strict linearity between temperatures which will be more inaccurate the larger the gaps \n",
    "## between surround temperatures\n",
    "## the primary purpose of this is not to give the most accurate interpolation of temperature data but to allow\n",
    "## us to create relatively reasonable temperature data to start the construction of models\n",
    "## more sophisticated models will be used for final model construction\n",
    "\n",
    "def basic_temp_interpolator(new_datetime_in: str):\n",
    "    \n",
    "    ##convert new_datetime into datetime data type from pandas\n",
    "    ##input should be in the format \"YYYY-mm-dd HH:MM:SS\"\n",
    "    new_datetime = pd.to_datetime(new_datetime_in)\n",
    "    \n",
    "    ##all data which occurs before new point\n",
    "    previous_temp_data = temperature_nsw[temperature_nsw['DATETIME'] <= new_datetime]\n",
    "    ##oldest point in that data, the point closest to the new data\n",
    "    previous_temp_data = previous_temp_data[previous_temp_data['DATETIME'] == max(previous_temp_data['DATETIME'])]\n",
    "    ##all data that occurs after new point\n",
    "    next_temp_data = temperature_nsw[temperature_nsw['DATETIME'] >= new_datetime]\n",
    "    ##newest point in that data, the point closest to the new data\n",
    "    next_temp_data = next_temp_data[next_temp_data['DATETIME'] == min(next_temp_data['DATETIME'])]\n",
    "    next_temp_data.reset_index()\n",
    "    previous_temp_data.reset_index()\n",
    "    \n",
    "    ##avoids a divison by zero error in the case of interpolation calling on data already in temp data\n",
    "    if previous_temp_data['DATETIME'].values[0] == new_datetime:\n",
    "        return(previous_temp_data['TEMPERATURE'])\n",
    "    \n",
    "    ##time between exisitng measurements\n",
    "    time_between_measurements = next_temp_data['DATETIME'].values[0] - previous_temp_data['DATETIME'].values[0]\n",
    "    ##time between new point and closest measurement before it\n",
    "    Previous_new_time_difference = new_datetime - previous_temp_data['DATETIME'].values[0]\n",
    "    ##time between new point and closest measurement after it\n",
    "    next_new_time_difference = time_between_measurements - Previous_new_time_difference\n",
    "    \n",
    "    ##this will be a measure of how close the new time is to the previous time 1 for equals 0 for equal to the next time\n",
    "    proportion_previous = next_new_time_difference/time_between_measurements\n",
    "    ##this will be the same as above but for the next time\n",
    "    proportion_next = 1- proportion_previous\n",
    "    \n",
    "    new_temp = proportion_previous*previous_temp_data['TEMPERATURE'].values[0] + proportion_next*next_temp_data['TEMPERATURE'].values[0]\n",
    "\n",
    "    return(new_temp)\n",
    "\n",
    "##compiles without error but may need testing with data type conversion\n",
    "##basic_temp_interpolator(\"2011-11-11 11:11:11\")\n",
    "##truedemand_nsw['TEMPERATURE'] = truedemand_nsw['DATETIME'].apply(basic_temp_interpolator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a3c7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "## time series methods\n",
    "\n",
    "## this will generate the average temperature for a defined time window either forwards or backwards\n",
    "def prior_temp_average(time: str = '2012-01-01 00:00:00'\n",
    "                       ,days: int = 0\n",
    "                       ,hours: int = 1\n",
    "                       ,minutes: int = 0\n",
    "                       ,wheighted: bool = False\n",
    "                       ,forward: bool = False):\n",
    "    ##turn input str into a date time\n",
    "    sample_datetime = pd.to_datetime(time)\n",
    "    \n",
    "    ##window of time before supplied date\n",
    "    if forward:\n",
    "        start_datetime = sample_datetime\n",
    "        finish_datetime = sample_datetime + np.timedelta64(days,'D') + np.timedelta64(hours,'h') + np.timedelta64(minutes,'m')\n",
    "    ##window of time after supplied date\n",
    "    else:\n",
    "        start_datetime = sample_datetime - np.timedelta64(days,'D') - np.timedelta64(hours,'h') - np.timedelta64(minutes,'m')\n",
    "        finish_datetime = sample_datetime\n",
    "    \n",
    "    \n",
    "    ##two methods wheighted = True will factor in the time around previous existing temperatures\n",
    "    ##wheighted = False will return unweighted average\n",
    "    if wheighted:\n",
    "        ##not implemented yet\n",
    "        return(None)\n",
    "    else:\n",
    "        temp_data = temperature_nsw[temperature_nsw['DATETIME'] <= finish_datetime]\n",
    "        temp_data = temp_data[start_datetime <= temp_data['DATETIME']]\n",
    "        return(temp_data.loc[:,'TEMPERATURE'].mean())\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
